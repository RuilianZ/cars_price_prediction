---
title: "Used Cars Price Prediction - Analysis"
author: "Roxy Zhang"
date: "3/21/2022"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(tidyverse)
library(stringr) # for data cleaning
library(patchwork) # align plots
library(caret)
library(ISLR)
library(pls)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .7,
  out.width = "95%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


## Objective
To predict the costs of used cars given the data collected from various sources and distributed across various locations in India.


## Data cleaning

```{r}
# re-level owner type
ord_owner_type = c("First", "Second", "Third", "Fourth")

# data import and cleaning
car = read_csv("data.csv") %>% 
  janitor::clean_names() %>% 
  select(- c(x1, new_price)) %>% 
  drop_na() %>% 
  filter(power != "null bhp") %>% 
  mutate(
    price = round(price * 1309.57, 0),
    name = gsub(" .*$", "", name),
    engine = gsub(" CC", "", engine),
    mileage = gsub(" .*$", "", mileage),
    power = gsub(" bhp", "", power),
    owner_type = gsub(" & Above", "", owner_type)) %>% 
  mutate(
    engine = as.numeric(engine),
    mileage = as.numeric(mileage),
    power = as.numeric(power),
    name = as.factor(name),
    location = as.factor(location),
    fuel_type = as.factor(fuel_type),
    transmission = as.factor(transmission),
    owner_type = as.factor(owner_type),
    owner_type = fct_relevel(owner_type, ord_owner_type),
    seats = as.factor(seats)
  ) %>% 
  filter(kilometers_driven != 6500000) %>% 
  select(name, location, fuel_type, transmission, owner_type, seats, everything())

# check abnormal value
car %>% 
  filter(kilometers_driven > 1000000) %>% 
  select(kilometers_driven) # 6500000

range(car$kilometers_driven)

range(car$year)

# check for NA
colSums(is.na(car))
```

For the response variable `price`, the original data used 100000 Indian Rupee as unit. For better illustration, we transformed it to USD, using the exchange rate of 100000 Indian Rupee equals to 1309.75 USD on March 21, 2022.  
For numeric variables with unit, the units are deleted for model-building.


## Exploratory Data Analysis

```{r}
# look at data summary
dim(car)

summary(car)

skimr::skim(car)
```

There are 11 predictors and 1 response variable - `price`.  
5 of the predictors are numeric, and the other 6 of them are categorical.

```{r}
# visualization for categorical variables
theme_set(
  theme_minimal() +
  #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  theme(legend.position = "none"))

p1 = car %>% 
  ggplot(aes(x = name, y = price, fill = name)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

p2 = car %>% 
  ggplot(aes(x = fuel_type, y = price, fill = fuel_type)) +
  geom_boxplot()

p3 = car %>% 
  ggplot(aes(x = transmission, y = price, fill = transmission)) +
  geom_boxplot()

p4 = car %>% 
  ggplot(aes(x = owner_type, y = price, fill = owner_type)) +
  geom_boxplot()

p5 = car %>% 
  ggplot(aes(x = seats, y = price, fill = seats)) +
  geom_boxplot()

(p2 + p3)/(p4 + p5)/(p1)
```

```{r}
# visualization for numeric variable year
# log transformation of price
car %>% 
  ggplot(aes(x = year, y = log(price))) + 
  geom_bar(stat = "identity", fill = "blue")
```


## Data partitioning

```{r}
index_train = createDataPartition(
  y = car$price,
  p = 0.8,
  list = FALSE
)

train_df = car[index_train, ]
test_df = car[-index_train, ]

train_x = model.matrix(price ~ ., train_df)[ ,-1]
train_y = train_df$price

test_x = model.matrix(price ~ ., test_df)[ , -1]
test_y = test_df$price
```


## Model building

Start from the simplest - try lm first

```{r}
lm_fit = lm(price ~ ., data = car)
#summary(lm_fit)
```

Adjusted R-squared:  0.7865 


### Lasso

```{r}
set.seed(0324)

lasso_fit = train(price ~ .,
                  data = train_df,
                  method = "glmnet",
                  preProcess = c("center", "scale", "zv"), # zv for zero variance
                  tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(4, -2, length = 100))),
                   trControl = trainControl(method = "cv"))

summary(lasso_fit)

# Plot RMSE against lambda
plot(lasso_fit, xTrans = log)

# Extract optimum lambda
lasso_fit$bestTune

# Extract coefficiencts
#as.matrix(round(coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda), 3))

# Make prediction on test data
lasso_predict = predict(lasso_fit, newdata = test_df)

# Calculate test RMSE
RMSE(lasso_predict, test_df$price)
```

### Elastic net

```{r}
set.seed(0324)

enet_fit <- train(x = train_x,
                  y = train_y,
                  method = "glmnet",
                  preProcess = c("center", "scale", "zv"),
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                         lambda = exp(seq(-2, 7, length = 100))),
                  trControl = trainControl(method = "cv"))

# Plot RMSE against lambda
myCol = rainbow(25)
myPar = list(superpose.symbol = list(col = myCol),
             superpose.line = list(col = myCol))

plot(enet_fit, par.settings = myPar, xTrans = log, xlim = c(4, 7))


# Extract optimum lambda
enet_fit$bestTune
```


### Principal components regression (PCR)

```{r}
set.seed(0324)

pcr_fit = train(x = train_x, 
                y = train_y,
                method = "pcr",
                tuneGrid = data.frame(ncomp = 1:40),
                trControl = trainControl(method = "cv"),
                preProcess = c("center", "scale", "zv")) 

summary(pcr_fit)

pcr_pred = predict(pcr_fit, newdata = test_x)

# test error: MSE
mean((test_y - pcr_pred) ^ 2)

ggplot(pcr_fit, highlight = TRUE) + theme_bw()
```


### Partial least squares (PLS)

```{r}
set.seed(0324)

pls_fit = train(x = train_x, 
                y = train_y,
                method = "pls",
                tuneGrid = data.frame(ncomp = 1:19),
                trControl = trainControl(method = "cv"),
                preProcess = c("center", "scale", "zv")) 

summary(pls_fit)

pls_pred = predict(pls_fit, newdata = test_x)

# test error: MSE
mean((test_y - pls_pred) ^ 2)

ggplot(pls_fit, highlight = TRUE) + theme_bw()
```


### Multivariate Adaptive Regression Spline (MARS)

```{r}
set.seed(0324)

mars_grid = expand.grid(
  degree = 1:3,
  nprune = 2:15)

mars_fit = train(x = train_x, 
                 y = train_y,
                 method = "earth",
                 tuneGrid = mars_grid,
                 trControl = trainControl(method = "cv"))

ggplot(mars_fit)

mars_fit$bestTune
```





## Model comparison

```{r}
resamp = resamples(list(lasso = lasso_fit, elastic_net = enet_fit,
                         pcr = pcr_fit, pls = pls_fit, mars = mars_fit))

summary(resamp)

bwplot(resamp, metric = "RMSE")
```

