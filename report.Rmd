---
title: "Used Cars Price Prediction Model Training"
author: "Roxy Zhang"
date: "3/25/2022"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
editor_options: 
  chunk_output_type: console
---

\newpage

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(caret)
library(ggcorrplot)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .7,
  out.width = "95%"
)

theme_set(theme_minimal() + theme(legend.position = 'bottom'))
```


# Introduction

Since the market of used cars is growing, there is an increasing need of the information of used cars prices. Therefore, I want to build a model predicting the price using attributes of the car as predictors, and thus provide information for the potential buyers for decision making.  

Our data is from [Kaggle](https://www.kaggle.com/code/kuanghiu/used-cars-price-prediction). This dataset contains 22 (1998-2019) years of used cars information. There are 5872 rows and 11 predictors, among which 5 are numeric and 6 are categorical.  


# Data Cleaning

For better illustration, I transformed the original unit (100000 Indian Rupee) of response variable **price** to USD, using the exchange rate of 100000 Indian Rupee equals to 1309.75 USD on March 21, 2022. For numeric variables with unit, the units are deleted for model-building. I also delete the car model from the original `name` variable, keeping only the brand name, since the model can be greatly explained by the predictors I are using. The type `Fourth` in owner_type is actually Fourth and above. For analysis completeness, I dropped NA values. I also filtered out a row containing an extremely large value of kilometers_driven.  


Below are the variable used:

**name**: The brand of the car.  
**location**: The location in which the car is being sold or is available for purchase.  
**year**: The year or edition of the model.  
**kilometers_driven**: The total kilometres driven in the car by the previous owner(s) in KM.  
**fuel_type**: The type of fuel used by the car.  
**transmission**: The type of transmission used by the car.  
**owner_type**: Whether the ownership is Firsthand, Second hand or other.  
**mileage**: The standard mileage offered by the car company in kmpl or km/kg.  
**engine**: The displacement volume of the engine in cc.  
**power**: The maximum power of the engine in bhp.  
**seats**: The number of seats in the car.  
**price**: The price of the used car in US Dollar. 

```{r data cleaning, include = FALSE}
# re-level owner type
ord_owner_type = c("First", "Second", "Third", "Fourth")

# data import and cleaning
car = read_csv("data.csv") %>% 
  janitor::clean_names() %>% 
  select(- c(x1, new_price)) %>% 
  drop_na() %>% 
  filter(power != "null bhp") %>% 
  mutate(
    price = round(price * 1309.57, 0),
    name = gsub(" .*$", "", name),
    engine = gsub(" CC", "", engine),
    mileage = gsub(" .*$", "", mileage),
    power = gsub(" bhp", "", power),
    owner_type = gsub(" & Above", "", owner_type)) %>% 
  mutate(
    engine = as.numeric(engine),
    mileage = as.numeric(mileage),
    power = as.numeric(power),
    name = as.factor(name),
    location = as.factor(location),
    fuel_type = as.factor(fuel_type),
    transmission = as.factor(transmission),
    owner_type = as.factor(owner_type),
    owner_type = fct_relevel(owner_type, ord_owner_type),
    seats = as.factor(seats)
  ) %>% 
  filter(kilometers_driven < 1000000) %>% 
  select(name, location, fuel_type, transmission, owner_type, seats, everything())

# abnormal value
car %>% 
  filter(kilometers_driven > 1000000) %>% 
  select(kilometers_driven) # 6500000
```

# Exploratory Data Analysis

```{r fig.asp = 0.4, echo=FALSE}
# visualization for numeric variable year
car %>% 
  ggplot(aes(x = year, y = log(price))) + 
  geom_bar(stat = "identity", fill = "blue")
```

First, I plot the price against year. For better scaling, the price is log-transformed. There is an increasing trend of price from 1998-2014, while the price goes down rapidly since 2015.

```{r fig.asp = 1.0, echo=FALSE}
# visualization for categorical variables
theme_set(
  theme_minimal() +
  #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  theme(legend.position = "none"))

p1 = car %>% 
  ggplot(aes(x = name, y = price, fill = name)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

p2 = car %>% 
  ggplot(aes(x = fuel_type, y = price, fill = fuel_type)) +
  geom_boxplot()

p3 = car %>% 
  ggplot(aes(x = transmission, y = price, fill = transmission)) +
  geom_boxplot()

p4 = car %>% 
  ggplot(aes(x = owner_type, y = price, fill = owner_type)) +
  geom_boxplot()

p5 = car %>% 
  ggplot(aes(x = seats, y = price, fill = seats)) +
  geom_boxplot()

(p2 + p3)/(p4 + p5)/(p1)
```

Then I look at the price distribution for 5 categorical predictors respectively. There are some interesting findings:  
1. There are several attributes associated with higher price: fuel type diesel, automatic transmission, first-hand owner, and cars with 2 seats.  
2. The price range for each brand varies a lot. For example, Lamborghini has a condensed price range slightly above 150k (which is not surprising), while the majority stays below 25k.  
3. There is a relatively large number of outliers observed, indicating the big variance of our response variable. This may because of the volatility of used cars market, which in turn suggests the significance of our project. 

```{r, echo = FALSE}
# correlation plot for all data
model.matrix(price ~ ., data = car %>% select(-name, -location))[ , -1] %>% 
  cor(use = "pairwise.complete.obs") %>% 
  ggcorrplot(type = "full", lab = TRUE, lab_size = 1.5, tl.cex = 10.0)
```

For better visualization, categorical variables with over ten terms (`name`, `location`) are filtered out in the correlation plot. From the upper-right corner of the plot we can see a strong positive correlation between `engine` and `power`. Besides, `milage` is negatively associated with both `engine` and `power`.  


# Data Partitioning

The data is splitted into training data and testing data by the proportion of 0.8:0.2.


# Model Building

What predictor variables did you include?
What technique did you use? What assumptions, if any, are being made by using this technique?
If there Ire tuning parameters, how did you pick their values?
Discuss the training/test performance if you have a test data set.
Which variables play important roles in predicting the response?
What are the limitations of the models you used (if there are any)? Are the models flexible enough to capture the underlying truth?
...


5 models are used to fit the training data: Lasso, Elastic Net, Principal components regression (PCR), Partial least squares (PLS), and Multivariate Adaptive Regression Spline (MARS). Cross validation is used to select the best parameter or parameter combination for each model.


### Lasso

The tuning parameter $\lambda$ controls the L1 regularization, as $\lambda$ increases, the number of predictors in the model decreases. Setting the candidate values of $\lambda$ to be from `r exp(-2)` to `r exp(4)` with 100 steps, the best-tune $\lambda$ is 2.069. 

### Elastic Net

Elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods.

### Principal components regression (PCR)


### Partial least squares (PLS)


### Multivariate Adaptive Regression Spline (MARS)



# Model limitations

The penalty function of Lasso has several limitations. For example (not the case of this data), in the "large p, small n" case (high-dimensional data with few examples), the Lasso selects at most n variables before it saturates. Also if there is a group of highly correlated variables, then the Lasso tends to select one variable from a group and ignore the others. As is mentioned above, there are some association among `power`, `engine` and `mileage`, thus the lasso model's performance is not so well. To overcome these limitations, the elastic net adds a quadratic part to the penalty, which when used alone is ridge regression.

# Conclusions

What Ire your findings? Are they what you expect? What insights into the data can you make?
